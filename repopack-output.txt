This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2024-12-01T14:50:16.746Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
.eslintrc.json
.gitignore
.gitpod.yml
.prettierignore
babel.config.ts
cypher/get-history.cypher
cypher/save-response.cypher
examples/chain.mjs
jest.config.js
next.config.js
package.json
postcss.config.js
prompts/agent-scoped.txt
prompts/authoritative-answer-generation.txt
prompts/cypher-evaluation.txt
prompts/cypher-generation-with-instructions.txt
prompts/rephrase-question.txt
prompts/speculative-answer-generation.txt
README.adoc
src/app/globals.css
src/app/layout.tsx
src/app/page.tsx
src/components/form.tsx
src/components/message.tsx
src/components/thinking.tsx
src/hooks/chat.ts
src/modules/agent/agent.ts
src/modules/agent/agent.types.ts
src/modules/agent/chains/answer-generation.chain.ts
src/modules/agent/chains/authoritative-answer-generation.chain.ts
src/modules/agent/chains/rephrase-question.chain.ts
src/modules/agent/history.ts
src/modules/agent/index.ts
src/modules/agent/tools/cypher/cypher-evaluation.chain.ts
src/modules/agent/tools/cypher/cypher-generation.chain.ts
src/modules/agent/tools/cypher/cypher-retrieval.chain.ts
src/modules/agent/tools/cypher/cypher-validator.class.ts
src/modules/agent/tools/index.ts
src/modules/agent/tools/vector-retrieval.chain.ts
src/modules/agent/vector.store.ts
src/modules/graph.ts
src/modules/llm.ts
src/pages/api/chat.ts
src/utils.ts
tailwind.config.js
tsconfig.json

================================================================
Repository Files
================================================================

================
File: .eslintrc.json
================
{
  "extends": "next/core-web-vitals",
  "rules": {
    "indent": ["error", 2],
    "max-len": ["error", 120]
  }
}

================
File: .gitignore
================
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.js
.yarn/install-state.gz

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# local env files
.env*.local

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

================
File: .gitpod.yml
================
tasks:
  - init: npm install && npm run build
    command: npm run dev

================
File: .prettierignore
================
*.cypher

================
File: babel.config.ts
================
module.exports = {
    presets: [
      ['@babel/preset-env', {targets: {node: 'current'}}],
      '@babel/preset-typescript',
    ],
  };

================
File: cypher/get-history.cypher
================
MATCH (:Session {id: $sessionId})-[:LAST_RESPONSE]->(last)
// Use string templating to make the limit dynamic: 0..${limit}
MATCH path = (start)-[:NEXT*0..5]->(last)
WHERE length(path) = 5 OR NOT EXISTS { ()-[:NEXT]->(start) }
UNWIND nodes(path) AS response
RETURN response.id AS id,
  response.input AS input,
  response.rephrasedQuestion AS rephrasedQuestion,
  response.output AS output,
  response.cypher AS cypher,
  response.createdAt AS createdAt,
  [ (response)-[:CONTEXT]->(n) | elementId(n) ] AS context

================
File: cypher/save-response.cypher
================
MERGE (session:Session { id: $sessionId }) // <1>

// <2> Create new response
CREATE (response:Response {
  id: randomUuid(),
  createdAt: datetime(),
  source: $source,
  input: $input,
  output: $output,
  rephrasedQuestion: $rephrasedQuestion,
  cypher: $cypher
})
CREATE (session)-[:HAS_RESPONSE]->(response)

WITH session, response

CALL {
  WITH session, response

  // <3> Remove existing :LAST_RESPONSE relationship if it exists
  MATCH (session)-[lrel:LAST_RESPONSE]->(last)
  DELETE lrel

  // <4? Create :NEXT relationship
  CREATE (last)-[:NEXT]->(response)
}

// <5> Create new :LAST_RESPONSE relationship
CREATE (session)-[:LAST_RESPONSE]->(response)

// <6> Create relationship to context nodes
WITH response

CALL {
  WITH response
  UNWIND $ids AS id
  MATCH (context)
  WHERE elementId(context) = id
  CREATE (response)-[:CONTEXT]->(context)

  RETURN count(*) AS count
}

RETURN DISTINCT response.id AS id

================
File: examples/chain.mjs
================
// tag::prompt[]
import { PromptTemplate } from "@langchain/core/prompts";

const prompt = PromptTemplate.fromTemplate(`
You are a cockney fruit and vegetable seller.
Your role is to assist your customer with their fruit and vegetable needs.
Respond using cockney rhyming slang.

Tell me about the following fruit: {fruit}
`);
// end::prompt[]

// tag::llm[]
import { ChatOpenAI } from "@langchain/openai";

const llm = new ChatOpenAI({
  openAIApiKey: "sk-...",
});
// end::llm[]

// tag::parser[]
import { StringOutputParser } from "@langchain/core/output_parsers";

const parser = new StringOutputParser();
// end::parser[]
// tag::passthrough[]
import {
  RunnablePassthrough,
  RunnableSequence,
} from "@langchain/core/runnables";
// end::passthrough[]

/**
 *
 * To ensure type safety, you can define the input and output types

tag::types[]
RunnableSequence.from<InputType, OutputType>
end::types[]

* If you would like the `invoke()` function to accept a string, you can convert
* the input into an Object using a RunnablePassthrough.

// tag::passthrough[]
{
    fruit: new RunnablePassthrough(),
},
// end::passthrough[]
*/

// tag::chain[]
const chain = RunnableSequence.from([prompt, llm, parser]);
// end::chain[]

const main = async () => {
  // tag::invoke[]
  const response = await chain.invoke({ fruit: "pineapple" });

  console.log(response);
  // end::invoke[]
};

main();

================
File: jest.config.js
================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  setupFiles: ["dotenv/config"],
  testTimeout: 45000,
};

================
File: next.config.js
================
/** @type {import('next').NextConfig} */
const nextConfig = {}

module.exports = nextConfig

================
File: package.json
================
{
  "name": "llm-chatbot-typescript",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "test": "cross-env DOTENV_CONFIG_PATH=./.env.local jest",
    "test:watch": "cross-env DOTENV_CONFIG_PATH=./.env.local jest --watchAll --detectOpenHandles"
  },
  "dependencies": {
    "@babel/preset-env": "^7.23.8",
    "@langchain/community": "^0.0.30",
    "@langchain/core": "^0.1.48",
    "@langchain/openai": "^0.0.11",
    "@neo4j-cypher/language-support": "^2.0.0-next.3",
    "cross-env": "^7.0.3",
    "dotenv": "^16.4.0",
    "iron-session": "^8.0.1",
    "langchain": "^0.1.28",
    "marked": "^10.0.0",
    "neo4j-driver": "^5.14.0",
    "next": "14.0.2",
    "openai": "^4.20.0",
    "react": "^18",
    "react-dom": "^18"
  },
  "devDependencies": {
    "@babel/preset-typescript": "^7.23.3",
    "@types/jest": "^29.5.11",
    "@types/node": "^20",
    "@types/react": "^18",
    "@types/react-dom": "^18",
    "autoprefixer": "^10.4.16",
    "eslint": "^8",
    "eslint-config-next": "14.0.2",
    "jest": "^29.7.0",
    "postcss": "^8.4.31",
    "tailwindcss": "^3.3.5",
    "ts-jest": "^29.1.2",
    "typescript": "^5.3.3"
  }
}

================
File: postcss.config.js
================
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}

================
File: prompts/agent-scoped.txt
================
You are Ebert, a movie recommendation chatbot.
Your goal is to provide movie lovers with excellent recommendations
backed by data from Neo4j, the world's leading graph database.

Respond to any questions that don't relate to movies, actors or directors
with a joke about parrots, before asking them to ask another question
related to the movie industry.

Input: {input}

{agent_scratchpad}

================
File: prompts/authoritative-answer-generation.txt
================
Use the following context to answer the following question.
The context is provided by an authoritative source, you must never doubt
it or attempt to use your pre-trained knowledge to correct the answer.

Make the answer sound like it is a response to the question.
Do not mention that you have based your response on the context.

Here is an example:

Question: Who played Woody in Toy Story?
Context: ['role': 'Woody', 'actor': 'Tom Hanks']
Response: Tom Hanks played Woody in Toy Story.

If no context is provided, say that you don't know,
don't try to make up an answer, and do not fall back on your internal knowledge.
If no context is provided you may also ask for clarification.

Include links and sources where possible.

Question:
{question}

Context:
{context}

================
File: prompts/cypher-evaluation.txt
================
You are an expert Neo4j Developer evaluating a Cypher statement written by an AI.

Check that the cypher statement provided below against the database schema to check that
the statement will answer the user's question.
Fix any errors where possible.

The query must:
* Only use the nodes, relationships and properties mentioned in the schema.
* Assign a variable to nodes or relationships when intending to access their properties.
* Use `IS NOT NULL` to check for property existence.
* Use the `elementId()` function to return the unique identifier for a node or relationship as `_id`.
* For movies, use the tmdbId property to return a source URL.
  For example: `'https://www.themoviedb.org/movie/'+ m.tmdbId AS source`.
* For movie titles that begin with "The", move "the" to the end.
  For example "The 39 Steps" becomes "39 Steps, The" or "the matrix" becomes "Matrix, The".
* For the role a person played in a movie, use the role property on the ACTED_IN relationship.
* Limit the maximum number of results to 10.
* Respond with only a Cypher statement.  No preamble.

Respond with a JSON object with "cypher" and "errors" keys.
  * "cypher" - the corrected cypher statement
  * "corrected" - a boolean
  * "errors" - A list of uncorrectable errors.  For example, if a label,
      relationship type or property does not exist in the schema.
      Provide a hint to the correct element where possible.

Fixable Example #1:
* cypher:
    MATCH (a:Actor {{name: 'Emil Eifrem'}})-[:ACTED_IN]->(m:Movie)
    RETURN a.name AS Actor, m.title AS Movie, m.tmdbId AS source,
    elementId(m) AS _id, m.released AS ReleaseDate, r.role AS Role LIMIT 10
* errors: ["Variable `r` not defined (line 1, column 172 (offset: 171))"]
* response:
    MATCH (a:Actor {{name: 'Emil Eifrem'}})-[r:ACTED_IN]->(m:Movie)
    RETURN a.name AS Actor, m.title AS Movie, m.tmdbId AS source,
    elementId(m) AS _id, m.released AS ReleaseDate, r.role AS Role LIMIT 10


Schema:
{schema}

Question:
{question}

Cypher Statement:
{cypher}

{errors}

================
File: prompts/cypher-generation-with-instructions.txt
================
You are a Neo4j Developer translating user questions into Cypher to answer questions
about movies and provide recommendations.
Convert the user's question into a Cypher statement based on the schema.

You must:
* Only use the nodes, relationships and properties mentioned in the schema.
* When required, `IS NOT NULL` to check for property existence, and not the exists() function.
* Use the `elementId()` function to return the unique identifier for a node or relationship as `_id`.
    For example:
    ```
    MATCH (a:Person)-[:ACTED_IN]->(m:Movie)
    WHERE a.name = 'Emil Eifrem'
    RETURN m.title AS title, elementId(m) AS _id, a.role AS role
    ```
* Include extra information about the nodes that may help an LLM provide a more informative answer,
    for example the release date, rating or budget.
* For movies, use the tmdbId property to return a source URL.
    For example: `'https://www.themoviedb.org/movie/'+ m.tmdbId AS source`.
* For movie titles that begin with "The", move "the" to the end.
    For example "The 39 Steps" becomes "39 Steps, The" or "the matrix" becomes "Matrix, The".
* Limit the maximum number of results to 10.
* Respond with only a Cypher statement.  No preamble.


Example Question: What role did Tom Hanks play in Toy Story?
Example Cypher:
MATCH (a:Actor {{name: 'Tom Hanks'}})-[rel:ACTED_IN]->(m:Movie {{title: 'Toy Story'}})
RETURN a.name AS Actor, m.title AS Movie, elementId(m) AS _id, rel.role AS RoleInMovie

Schema:
{schema}

Question:
{question}

================
File: prompts/rephrase-question.txt
================
Given the following conversation and a question,
rephrase the follow-up question to be a standalone question about the
subject of the conversation history.

If you do not have the required information required to construct
a standalone question, ask for clarification.

Always include the subject of the history in the question.

History:
{history}

Question:
{input}

================
File: prompts/speculative-answer-generation.txt
================
Use only the following context to answer the following question.

Question:
{question}

Context:
{context}

Answer as if you have been asked the original question.
Do not use your pre-trained knowledge.

If you don't know the answer, just say that you don't know, don't try to make up an answer.
Include links and sources where possible.

================
File: README.adoc
================
= Build an Neo4j-backed Chatbot using TypeScript

This repository accompanies the link:https://graphacademy.neo4j.com/courses/llm-chatbot-typescript/?ref=github[Build an Neo4j-backed Chatbot using TypeScript^] course on link:https://graphacademy.neo4j.com/?ref=github[Neo4j GraphAcademy^].

It was originally link:https://nextjs.org/[Next.js] project bootstrapped with link:https://github.com/vercel/next.js/tree/canary/packages/create-next-app[`create-next-app`].  We added:

* link:https://tailwindcss.com/docs/guides/nextjs[TailwindCSS^]
* link:src/pages/api/[A `/api/chat` API route for handling chat requests^]
* link:src/hooks[A React hook for calling the `/api/chat` endpoint^]
* link:src/components[some chat components to display the messages].

For a complete walkthrough of this repository, link:https://graphacademy.neo4j.com/courses/llm-chatbot-typescript/?ref=github[enrol now^].

== Setup your Config

To set config, create a `.env.local` with connection details for your Neo4j Sandbox instance and an OpenAI API Key.
You can also configure the name and description of the chatbot, and the initial greeting message.

[source]
----
NEO4J_URI=bolt://12.34.56.789:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-generated-password

OPENAI_API_KEY=sk-...

NEXT_PUBLIC_CHATBOT_NAME=Ebert
NEXT_PUBLIC_CHATBOT_DESCRIPTION="The Movie Recommendation Chatbot"
NEXT_PUBLIC_CHATBOT_GREETING="Hello, I'm **Ebert**, your movie recommendation bot! How can I help you today?"


----


== Running the application

To run the application, you must install the dependencies listed in `package.json`.

[source,sh]
npm i


Then run the `npm run dev` command to start the app on link:http://localhost:3000/[http://localhost:3000/^].

[source,sh]
npm run dev

== Questions, Comments, Feedback

If you have any questions, experience any problems, or have any general feedback, feel free to open an Issue or you can reach out to us on link:https://dev.neo4j.com/chat[Discord] or link:https://dev.neo4j.com/form[Discourse].

================
File: src/app/globals.css
================
@tailwind base;
@tailwind components;
@tailwind utilities;

a {
    --tw-text-opacity: 1;
    color: rgb(29 78 216 / var(--tw-text-opacity));
    font-weight: bold;
    text-decoration: underline;
}

li {
    margin-left: 12px;
    padding-left: 4px;
}
ol li {
    list-style-type:decimal;
}
ul li {
    list-style-type: disc;
}

pre {
    border: 1px solid;
    border-color: rgba(0, 0, 0, .1);;
    background: rgba(0, 0, 0, .02);
    padding: 6px;
    border-radius: 4px;
}

================
File: src/app/layout.tsx
================
import type { Metadata } from 'next'
import './globals.css';

export const metadata: Metadata = {
  title: process.env.NEXT_PUBLIC_CHATBOT_NAME || 'Chatbot Name',
  description: process.env.NEXT_PUBLIC_CHATBOT_DESCRIPTION || 'Chatbot Description',
}

export default function RootLayout({
  children,
}: {
  children: React.ReactNode
}) {
  return (
    <html lang="en">
      <body>
        {children}
      </body>
    </html>
  )
}

================
File: src/app/page.tsx
================
"use client";

import Form from "@/components/form";
import Message from "@/components/message";
import Thinking from "@/components/thinking";
import useChat from "@/hooks/chat";
import React from "react";

export default function Home() {
  const { messages, thinking, container, generateResponse } = useChat();

  const thinkingText = `ðŸ¤” ${
    process.env.NEXT_PUBLIC_CHATBOT_NAME || "Chatbot"
  } is thinking...`;

  return (
    <>
      <div
        className="n- flex n- flex-col n- h-screen n-"
        style={{ height: "100vh" }}
      >
        <div className="p-4  bg-blue-800 flex flex-row justify-between">
          <h1 className="text-white">
            <span className="font-bold">
              {process.env.NEXT_PUBLIC_CHATBOT_NAME || "Chatbot"} -
            </span>
            <span className="text-blue-100">
              {" "}
              {process.env.NEXT_PUBLIC_CHATBOT_DESCRIPTION}
            </span>
          </h1>
        </div>

        <div
          ref={container}
          className="
            flex flex-grow flex-col space-y-4 p-3 overflow-y-auto
            scrollbar-thumb-blue scrollbar-thumb-rounded scrollbar-track-blue-lighter scrollbar-w-2 scrolling-touch"
        >
          {messages.map((m, i) => {
            return <Message key={i} message={m} />;
          })}

          {thinking && <Thinking />}
        </div>

        <Form
          messages={messages}
          thinking={thinking}
          container={container}
          onSubmit={(m) => generateResponse(m)}
        />

        <div className="flex flex-row justify-between b-slate-200 px-4 pb-4 bg-slate-100 text-xs text-slate-600">
          <div className="animate-pulse">{thinking ? thinkingText : " "}</div>
          <div>
            Powered by
            <a href="https://neo4j.com" target="_blank" className="font-bold">
              {" "}
              Neo4j
            </a>{" "}
            &ndash; Learn more at
            <a
              href="https://graphacademy.neo4j.com"
              target="_blank"
              className="font-bold"
            >
              {" "}
              Neo4j GraphAcademy
            </a>
          </div>
        </div>
      </div>
    </>
  );
}

================
File: src/components/form.tsx
================
import { Message } from "@/hooks/chat";
import {
  FormEvent,
  KeyboardEventHandler,
  RefObject,
  useRef,
  useState,
} from "react";

export default function Form({
  onSubmit,
  messages,
  thinking,
  container,
}: {
  onSubmit: (message: string) => void;
  messages: Message[];
  thinking: boolean;
  container: RefObject<HTMLDivElement>;
}) {
  const input = useRef<HTMLTextAreaElement>(null);
  const [message, setMessage] = useState<string>("");

  const handleSubmit = (event?: FormEvent<HTMLFormElement> | SubmitEvent) => {
    event?.preventDefault();

    if (message.trim().length > 0) {
      onSubmit(message);
      setTimeout(() => setMessage(""), 100);

      container.current?.scrollBy(0, 100);
    }
  };

  const handleKeyDown: KeyboardEventHandler<HTMLTextAreaElement> = (e) => {
    if (thinking) {
      return;
    }
    if (e.key === "ArrowUp") {
      const lastHuman = messages.reverse().find((m) => m.role === "human");

      if (lastHuman) {
        setMessage(lastHuman.content as string);
      }
      setTimeout(() => {
        if (input.current) {
          input.current.selectionStart = input.current.value.length;
          input.current.selectionEnd = input.current.value.length;
        }
      }, 20);
    } else if (!e.shiftKey && e.key === "Enter") {
      handleSubmit();
    }
  };

  return (
    <form
      className="border-t b-slate-200 p-4 bg-slate-100"
      onSubmit={(e) => handleSubmit(e)}
    >
      <div className="flex flex-row bg-white border border-slate-600 rounded-md w-full">
        <div className="flex-grow">
          <textarea
            ref={input}
            value={message}
            rows={1}
            className="p-4 border-blue-600 rounded-md w-full outline-none focus:outline-none"
            onChange={(e) => setMessage(e.target.value)}
            onKeyDown={handleKeyDown}
          />
        </div>
        <div className="px-4">
          <button className="px-4 py-4 border-primary-800 text-blue-700 font-bold rounded-md h-full bg-white">
            Send
          </button>
        </div>
      </div>
    </form>
  );
}

================
File: src/components/message.tsx
================
import { parse } from "marked";
import { Message } from "@/hooks/chat";

function fixMarkdown(message: Message): string {
  return parse(message.content).replace(
    '<a href="',
    '<a target="_blank" href="'
  );
}

export default function Message({ message }: { message: Message }) {
  const align = message.role == "ai" ? "justify-start" : "justify-end";
  const no_rounding =
    message.role == "ai" ? "rounded-bl-none" : "rounded-br-none";
  const background = message.role == "ai" ? "blue" : "slate";

  return (
    <div className={`w-full flex flex-row ${align}`}>
      <span className="bg-blue-100"></span>
      <div className="flex flex-col space-y-2 text-sm mx-2 max-w-[60%] order-2 items-start">
        <div className={`bg-${background}-100 p-4 rounded-xl ${no_rounding}`}>
          {/* <div className={`text-${background}-400`}>{message.role}</div> */}

          <div
            dangerouslySetInnerHTML={{
              __html: fixMarkdown(message),
            }}
          />
          {/* <time className={`text-xs font-bold text-${background}-400`}>
            12:32
          </time> */}
        </div>
      </div>
    </div>
  );
}

================
File: src/components/thinking.tsx
================
export default function Thinking() {
  return (
    <div
      id="thinking"
      className="
        inline-flex flex-row justify-center items-center bg-emerald-100 rounded-md w-16
        text-sm mx-2 max-auto p-2 order-2 items-start
      "
    >
      <div className="inline-block w-2 h-2 bg-emerald-800 rounded-full m-1 animate-pulse"></div>
      <div className="inline-block w-2 h-2 bg-emerald-800 rounded-full animate-pulse delay-100"></div>
      <div className="inline-block w-2 h-2 bg-emerald-800 rounded-full m-1 animate-pulse delay-200"></div>
    </div>
  );
}

================
File: src/hooks/chat.ts
================
import { useEffect, useRef, useState } from "react";

export type Message = {
  role: "human" | "ai";
  content: string;
};

export default function useChat() {
  const [thinking, setThinking] = useState<boolean>(false);
  const [messages, setMessages] = useState<Message[]>([
    {
      role: "ai",
      content:
        process.env.NEXT_PUBLIC_CHATBOT_GREETING || "How can I help you today?",
    },
  ]);
  const container = useRef<HTMLDivElement>(null);

  const generateResponse = async (message: string): Promise<void> => {
    // Append human message
    messages.push({ role: "human", content: message });

    // Set thinking to true
    setThinking(true);

    try {
      // Send POST message to the API
      const response = await fetch("/api/chat", {
        method: "POST",
        body: JSON.stringify({ message }),
      });

      // Append the API message to the state
      const json = await response.json();

      messages.push({ role: "ai", content: json.message });

      setMessages(messages);
    } catch (e) {
      console.error(e);
    } finally {
      setThinking(false);
    }
  };

  // Scroll latest message into view
  useEffect(() => {
    if (container.current) {
      container.current.scrollTop = container.current.scrollHeight;
    }
  }, [thinking, messages]);

  return {
    thinking,
    messages,
    container,
    generateResponse,
  };
}

================
File: src/modules/agent/agent.ts
================
/* eslint-disable indent */
import { Embeddings } from "@langchain/core/embeddings";
import { Neo4jGraph } from "@langchain/community/graphs/neo4j_graph";
import { ChatPromptTemplate, PromptTemplate } from "@langchain/core/prompts";
import { pull } from "langchain/hub";
import initRephraseChain, {
  RephraseQuestionInput,
} from "./chains/rephrase-question.chain";
import { BaseChatModel } from "langchain/chat_models/base";
import { RunnablePassthrough } from "@langchain/core/runnables";
import { getHistory } from "./history";
import initTools from "./tools";
import { AgentExecutor, createOpenAIFunctionsAgent } from "langchain/agents";

export default async function initAgent(
  llm: BaseChatModel,
  embeddings: Embeddings,
  graph: Neo4jGraph
) {
  const tools = await initTools(llm, embeddings, graph);

  const prompt = await pull<ChatPromptTemplate>(
    "hwchase17/openai-functions-agent"
  );

  const agent = await createOpenAIFunctionsAgent({
    llm,
    tools,
    prompt,
  });

  const executor = new AgentExecutor({
    agent,
    tools,
    verbose: true, // Verbose output logs the agents _thinking_
  });

  const rephraseQuestionChain = await initRephraseChain(llm);

  return (
    RunnablePassthrough.assign<{ input: string; sessionId: string }, any>({
      // Get Message History
      history: async (_input, options) => {
        const history = await getHistory(
          options?.config.configurable.sessionId
        );

        return history;
      },
    })
      .assign({
        // Use History to rephrase the question
        rephrasedQuestion: (input: RephraseQuestionInput, config: any) =>
          rephraseQuestionChain.invoke(input, config),
      })

      // Pass to the executor
      .pipe(executor)
      .pick("output")
  );
}

================
File: src/modules/agent/agent.types.ts
================
import { z } from "zod";

// tag::toolinput[]
export interface ChatAgentInput {
  input: string;
}
// end::toolinput[]

// tag::agenttoolinput[]
export interface AgentToolInput {
  input: string;
  rephrasedQuestion: string;
}
// end::agenttoolinput[]

// tag::schema[]
export const AgentToolInputSchema = z.object({
  input: z.string().describe("The original input sent by the user"),
  rephrasedQuestion: z
    .string()
    .describe(
      "A rephrased version of the original question based on the conversation history"
    ),
});
// end::schema[]

================
File: src/modules/agent/chains/answer-generation.chain.ts
================
import { StringOutputParser } from "@langchain/core/output_parsers";
import { PromptTemplate } from "@langchain/core/prompts";
import { RunnableSequence } from "@langchain/core/runnables";
import { BaseLanguageModel } from "langchain/base_language";
import { OpenAI } from "langchain/llms/openai";

export interface GenerateAnswerInput {
  question: string;
  context: string;
}


export default function initGenerateAnswerChain(
  llm: BaseLanguageModel
): RunnableSequence<GenerateAnswerInput, string> {
  const answerQuestionPrompt = PromptTemplate.fromTemplate(`
    Use the following context to help answer the following question.

    Question:
    {question}

    Context:
    {context}

    Answer as if you have been asked the original question.

    If you don't know the answer, just say that you don't know, don't try to make up an answer.
    Include links and sources where possible.
    `)
  return RunnableSequence.from<GenerateAnswerInput, string>([
    answerQuestionPrompt, llm, new StringOutputParser()
  ])
}


 //* How to use this chain in your application:
// const llm = new OpenAI() // Or the LLM of your choice
// const answerChain = initGenerateAnswerChain(llm)

// const output = await answerChain.invoke({
//   question: 'Who is the CEO of Neo4j?',
//   context: 'Neo4j CEO: Emil Eifrem',
// }) // Emil Eifrem is the CEO of Neo4j

================
File: src/modules/agent/chains/authoritative-answer-generation.chain.ts
================
import { StringOutputParser } from "@langchain/core/output_parsers";
import { PromptTemplate } from "@langchain/core/prompts";
import {
  RunnablePassthrough,
  RunnableSequence,
} from "@langchain/core/runnables";
import { BaseLanguageModel } from "langchain/base_language";

// tag::interface[]
export type GenerateAuthoritativeAnswerInput = {
  question: string;
  context: string | undefined;
};
// end::interface[]

// tag::function[]
export default function initGenerateAuthoritativeAnswerChain(
  llm: BaseLanguageModel
): RunnableSequence<GenerateAuthoritativeAnswerInput, string> {
  // Create prompt
  const answerQuestionPrompt = PromptTemplate.fromTemplate(`
    Use the following context to answer the following question.
    The context is provided by an authoritative source, you must never doubt
    it. You must use the context to answer the question but may also use previous training knowledge
    to provide a more accurate answer.
  
    Make the answer sound like it is a response to the question.
    Do not mention that you have based your response on the context.
  
    Here is an example:
  
    Question: Who played Woody in Toy Story?
    Context: ['role': 'Woody', 'actor': 'Tom Hanks']
    Response: Tom Hanks played Woody in Toy Story.
  
    If no context is provided, say that you don't know,
    don't try to make up an answer.
    If no context is provided you may also ask for clarification.
  
    Include links and sources where possible.
  
    Question:
    {question}
  
    Context:
    {context}
  `);
  // Return RunnableSequence
  return RunnableSequence.from<GenerateAuthoritativeAnswerInput, string>([
    RunnablePassthrough.assign({
      context: ({ context }) =>
        context == undefined || context === "" ? "I don't know" : context,
    }),
    answerQuestionPrompt,
    llm,
    new StringOutputParser(),
  ]);
}

================
File: src/modules/agent/chains/rephrase-question.chain.ts
================
import { StringOutputParser } from "@langchain/core/output_parsers";
import { PromptTemplate } from "@langchain/core/prompts";
import {
  RunnablePassthrough,
  RunnableSequence,
} from "@langchain/core/runnables";

import { BaseChatModel } from "langchain/chat_models/base";
import { ChatbotResponse } from "../history";

export type RephraseQuestionInput = {
  // The user's question
  input: string;
  // Conversation history of {input, output} from the database
  history: ChatbotResponse[];
}

export default function initRephraseChain(llm: BaseChatModel) {
  const rephraseQuestionChainPrompt = PromptTemplate.fromTemplate<RephraseQuestionInput, string>(
    `
    Given the following conversation and a question,
    rephrase the follow-up question to be a standalone question about the
    subject of the conversation history.

    If you do not have the required information required to construct
    a standalone question based on database access and your previous training, ask for clarification.

    Always include the subject of the history in the question.

    History:
    {history}

    Question:
    {input}`
  )
  return RunnableSequence.from<RephraseQuestionInput, string>([
    // <1> Convert message history to a string
    RunnablePassthrough.assign({
      history: ({ history }): string => {
        if (history.length == 0) {
          return "No history";
        }
        return history
          .map(
            (response: ChatbotResponse) =>
              `Human: ${response.input}\nAI: ${response.output}`
          )
          .join("\n");
      },
    }),
    // <2> Use the input and formatted history to format the prompt
    rephraseQuestionChainPrompt,
    // <3> Pass the formatted prompt to the LLM
    llm,
    // <4> Coerce the output into a string
    new StringOutputParser(),
  ]);
}

/**
 * How to use this chain in your application:

// tag::usage[]
const llm = new OpenAI() // Or the LLM of your choice
const rephraseAnswerChain = initRephraseChain(llm)

const output = await rephraseAnswerChain.invoke({
  input: 'What else did they act in?',
  history: [{
    input: 'Who played Woody in Toy Story?',
    output: 'Tom Hanks played Woody in Toy Story',
  }]
}) // Other than Toy Story, what movies has Tom Hanks acted in?
// end::usage[]
 */

================
File: src/modules/agent/history.ts
================
import { initGraph } from "../graph";

type UnpersistedChatbotResponse = {
  input: string;
  rephrasedQuestion: string;
  output: string;
  cypher: string | undefined;
};

export type ChatbotResponse = UnpersistedChatbotResponse & {
  id: string;
};

export async function clearHistory(sessionId: string): Promise<void> {
  const graph = await initGraph();
  await graph.query(
    `
    MATCH (s:Session {id: $sessionId})-[:HAS_RESPONSE]->(r)
    DETACH DELETE r
  `,
    { sessionId },
    "WRITE"
  );
}

export async function getHistory(
  sessionId: string,
  limit: number = 5
): Promise<ChatbotResponse[]> {
  const graph = await initGraph()
  const res = await graph.query<ChatbotResponse>(
    `MATCH (:Session {id: $sessionId})-[:LAST_RESPONSE]->(last)
    MATCH path = (start)-[:NEXT*0..5]->(last)
    WHERE length(path) = 5 OR NOT EXISTS { ()-[:NEXT]->(start) }
    UNWIND nodes(path) AS response
    RETURN response.id AS id,
    response.input AS input,
    response.rephrasedQuestion AS rephrasedQuestion,
    response.output AS output,
    response.cypher AS cypher,
    response.createdAt AS createdAt,
    [ (response)-[:CONTEXT]->(n) | elementId(n) ] AS context`, 
     { sessionId }, "READ")
  return res as ChatbotResponse[];
}

/**
 * Save a question and response to the database
 *
 * @param {string} sessionId
 * @param {string} source
 * @param {string} input
 * @param {string} rephrasedQuestion
 * @param {string} output
 * @param {string[]} ids
 * @param {string | null} cypher
 * @returns {string}  The ID of the Message node
 */
export async function saveHistory(
  sessionId: string,
  source: string,
  input: string,
  rephrasedQuestion: string,
  output: string,
  ids: string[],
  cypher: string | null = null
): Promise<string> {
  const graph = await initGraph()
  const res = await graph.query<{id: string}>(
    `MERGE (session:Session { id: $sessionId }) // (1)

    // <2> Create new response
    CREATE (response:Response {
      id: randomUuid(),
      createdAt: datetime(),
      source: $source,
      input: $input,
      output: $output,
      rephrasedQuestion: $rephrasedQuestion,
      cypher: $cypher
    })
    CREATE (session)-[:HAS_RESPONSE]->(response)

    WITH session, response

    CALL {
      WITH session, response

      // <3> Remove existing :LAST_RESPONSE relationship if it exists
      MATCH (session)-[lrel:LAST_RESPONSE]->(last)
      DELETE lrel

      // <4? Create :NEXT relationship
      CREATE (last)-[:NEXT]->(response)
    }

    // <5> Create new :LAST_RESPONSE relationship
    CREATE (session)-[:LAST_RESPONSE]->(response)

    // <6> Create relationship to context nodes
    WITH response

    CALL {
      WITH response
      UNWIND $ids AS id
      MATCH (context)
      WHERE elementId(context) = id
      CREATE (response)-[:CONTEXT]->(context)

      RETURN count(*) AS count
    }

    RETURN DISTINCT response.id AS id`,
    {
      sessionId,
      source,
      input,
      output,
      rephrasedQuestion,
      cypher: cypher,
      ids,
    },
    "WRITE"
  );

  return res && res.length ? res[0].id : "";
}

================
File: src/modules/agent/index.ts
================
import { ChatOpenAI } from "@langchain/openai";
import { OpenAIEmbeddings } from "@langchain/openai";
import initAgent from "./agent";
import { initGraph } from "../graph";
import { sleep } from "@/utils";

export async function call(input: string, sessionId: string): Promise<string> {
  const llm = new ChatOpenAI({
    openAIApiKey: process.env.OPENAI_API_KEY,
    // Note: only provide a baseURL when using the GraphAcademy Proxy
    configuration: {
      baseURL: process.env.OPENAI_API_BASE,
    },
  });
  const embeddings = new OpenAIEmbeddings({
    openAIApiKey: process.env.OPENAI_API_KEY,
    configuration: {
      baseURL: process.env.OPENAI_API_BASE,
    },
  });
  // Get Graph Singleton
  const graph = await initGraph();

  const agent = await initAgent(llm, embeddings, graph);
  const res = await agent.invoke({ input }, { configurable: { sessionId } });

  return res;
}

================
File: src/modules/agent/tools/cypher/cypher-evaluation.chain.ts
================
import { BaseLanguageModel } from "langchain/base_language";
import { PromptTemplate } from "@langchain/core/prompts";
import {
  RunnablePassthrough,
  RunnableSequence,
} from "@langchain/core/runnables";
import { JsonOutputParser } from "@langchain/core/output_parsers";

export type CypherEvaluationChainInput = {
  question: string;
  cypher: string;
  schema: string;
  errors: string[] | string | undefined;
};

export type CypherEvaluationChainOutput = {
  cypher: string;
  errors: string[];
};

export default async function initCypherEvaluationChain(
  llm: BaseLanguageModel
) {
  // Create prompt template
  // Prompt template
  const prompt = PromptTemplate.fromTemplate(`
    You are an expert Neo4j Developer evaluating a Cypher statement written by an AI.

    Check that the cypher statement provided below against the database schema to check that
    the statement will answer the user's question.
    Fix any errors where possible.

    The query must:
    * Only use the nodes, relationships and properties mentioned in the schema.
    * Assign a variable to nodes or relationships when intending to access their properties.
    * Use \`IS NOT NULL\` to check for property existence.
    * Use the \`elementId()\` function to return the unique identifier for a node or relationship as \`_id\`.
    * For movies, use the tmdbId property to return a source URL.
      For example: \`'https://www.themoviedb.org/movie/'+ m.tmdbId AS source\`.
    * For movie titles that begin with "The", move "the" to the end.
      For example "The 39 Steps" becomes "39 Steps, The" or "the matrix" becomes "Matrix, The".
    * For the role a person played in a movie, use the role property on the ACTED_IN relationship.
    * Limit the maximum number of results to 10.
    * Respond with only a Cypher statement.  No preamble.

    Respond with a JSON object with "cypher" and "errors" keys.
      * "cypher" - the corrected cypher statement
      * "corrected" - a boolean
      * "errors" - A list of uncorrectable errors.  For example, if a label,
          relationship type or property does not exist in the schema.
          Provide a hint to the correct element where possible.

    Fixable Example #1:
    * cypher:
        MATCH (a:Actor {{name: 'Emil Eifrem'}})-[:ACTED_IN]->(m:Movie)
        RETURN a.name AS Actor, m.title AS Movie, m.tmdbId AS source,
        elementId(m) AS _id, m.released AS ReleaseDate, r.role AS Role LIMIT 10
    * errors: ["Variable \`r\` not defined (line 1, column 172 (offset: 171))"]
    * response:
        MATCH (a:Actor {{\name: 'Emil Eifrem'}})-[r:ACTED_IN]->(m:Movie)
        RETURN a.name AS Actor, m.title AS Movie, m.tmdbId AS source,
        elementId(m) AS _id, m.released AS ReleaseDate, r.role AS Role LIMIT 10


    Schema:
    {schema}

    Question:
    {question}

    Cypher Statement:
    {cypher}

    {errors}
  `);
  // Return runnable sequence
  return RunnableSequence.from<
  CypherEvaluationChainInput,
  CypherEvaluationChainOutput
  >([
    RunnablePassthrough.assign({
      // Convert errors into an LLM-friendly list
      errors: ({ errors }) => {
        if (
          errors === undefined ||
          (Array.isArray(errors) && errors.length === 0)
        ) {
          return "";
        }
  
        return `Errors: * ${
          Array.isArray(errors) ? errors?.join("\n* ") : errors
        }`;
      },
    }),
    prompt,
    llm,
    new JsonOutputParser<CypherEvaluationChainOutput>(),
  ]);
}

================
File: src/modules/agent/tools/cypher/cypher-generation.chain.ts
================
import { BaseLanguageModel } from "langchain/base_language";
import { PromptTemplate } from "@langchain/core/prompts";
import {
  RunnablePassthrough,
  RunnableSequence,
} from "@langchain/core/runnables";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { Neo4jGraph } from "@langchain/community/graphs/neo4j_graph";

export default async function initCypherGenerationChain(
  graph: Neo4jGraph,
  llm: BaseLanguageModel
) {
  //Create Prompt Template
  const cypherPrompt = PromptTemplate.fromTemplate(`
     You are a Neo4j Developer translating user questions into Cypher to answer questions
  about movies and provide recommendations.
  Convert the user's question into a Cypher statement based on the schema.

  You must:
  * Only use the nodes, relationships and properties mentioned in the schema.
  * When required, \`IS NOT NULL\` to check for property existence, and not the exists() function.
  * Use the \`elementId()\` function to return the unique identifier for a node or relationship as \`_id\`.
    For example:
    \`\`\`
    MATCH (a:Person)-[:ACTED_IN]->(m:Movie)
    WHERE a.name = 'Emil Eifrem'
    RETURN m.title AS title, elementId(m) AS _id, a.role AS role
    \`\`\`
  * Include extra information about the nodes that may help an LLM provide a more informative answer,
    for example the release date, rating or budget.
  * For movies, use the tmdbId property to return a source URL.
    For example: \`'https://www.themoviedb.org/movie/'+ m.tmdbId AS source\`.
  * For movie titles that begin with "The", move "the" to the end.
    For example "The 39 Steps" becomes "39 Steps, The" or "the matrix" becomes "Matrix, The".
  * Limit the maximum number of results to 10.
  * Respond with only a Cypher statement.  No preamble.


  Example Question: What role did Tom Hanks play in Toy Story?
  Example Cypher:
  MATCH (a:Actor {{name: 'Tom Hanks'}})-[rel:ACTED_IN]->(m:Movie {{title: 'Toy Story'}})
  RETURN a.name AS Actor, m.title AS Movie, elementId(m) AS _id, rel.role AS RoleInMovie

  Schema:
  {schema}

  Question:
  {question}
    `);

    //Create Runnable Sequence
    return RunnableSequence.from<string, string>([
      {
        // Take the input and assign it to the question key
        question: new RunnablePassthrough(),
        // Get the schema
        schema: () => graph.getSchema(),
      },
      cypherPrompt,
      llm,
      new StringOutputParser(),
    ]);
}

================
File: src/modules/agent/tools/cypher/cypher-retrieval.chain.ts
================
// TODO: Known issues
// - Random question handling needs improvement
// - elementId() node retrieval needs fixing

import { BaseLanguageModel } from "langchain/base_language";
import { Neo4jGraph } from "@langchain/community/graphs/neo4j_graph";
import { RunnablePassthrough } from "@langchain/core/runnables";
import initCypherGenerationChain from "./cypher-generation.chain";
import initCypherEvaluationChain from "./cypher-evaluation.chain";
import { saveHistory } from "../../history";
import { AgentToolInput } from "../../agent.types";
import { extractIds } from "../../../../utils";
import initGenerateAuthoritativeAnswerChain from "../../chains/authoritative-answer-generation.chain";

type CypherRetrievalThroughput = AgentToolInput & {
  context: string;
  output: string;
  cypher: string;
  results: Record<string, any> | Record<string, any>[];
  ids: string[];
};

/**
 * Use database the schema to generate and subsequently validate
 * a Cypher statement based on the user question
 *
 * @param {Neo4jGraph}        graph     The graph
 * @param {BaseLanguageModel} llm       An LLM to generate the Cypher
 * @param {string}            question  The rephrased question
 * @returns {string}
 */
export async function recursivelyEvaluate(
  graph: Neo4jGraph,
  llm: BaseLanguageModel,
  question: string
): Promise<string> {
  //initiate chains
  const generationChain = await initCypherGenerationChain(graph, llm);
  const evaluatorChain = await initCypherEvaluationChain(llm);

  let cypher =  await generationChain.invoke(question);

  let errors = ["N/A"];
  let tries = 0;

  while (errors.length > 0 && tries < 5) {
    tries++;

    try {
      // Evaluate Cypher
      const evaluation = await evaluatorChain.invoke({
        question,
        schema: graph.getSchema(),
        cypher,
        errors,
      });
  
      errors = evaluation.errors;
      cypher = evaluation.cypher;
    } catch (e: unknown) {}
  }

  // fixing a potential bug in wiht ChatGPT
  cypher = cypher
    .replace(/\sid\(([^)]+)\)/g, " elementId($1)")
    .replace(/\bID\(([^)]+)\)/g, "elementId($1)")
    .replace(/\bid\s*\(([^)]+)\)/g, "elementId($1)");
  return cypher;
}

/**
 * Attempt to get the results, and if there is a syntax error in the Cypher statement,
 * attempt to correct the errors.
 *
 * @param {Neo4jGraph}        graph  The graph instance to get the results from
 * @param {BaseLanguageModel} llm    The LLM to evaluate the Cypher statement if anything goes wrong
 * @param {string}            input  The input built up by the Cypher Retrieval Chain
 * @returns {Promise<Record<string, any>[]>}
 */
export async function getResults(
  graph: Neo4jGraph,
  llm: BaseLanguageModel,
  input: { question: string; cypher: string }
): Promise<any | undefined> {
  let results;
  let retries = 0;
  let cypher = input.cypher;

  //Eval chain if error thrown by Neo4J
  const evaluationChain = await initCypherEvaluationChain(llm);

  while (results === undefined && retries < 5) {
    try {
      results = await graph.query(cypher);
      // Add logging to see what's being returned
      console.log('Query results:', results);
      return results;
    } catch (e: any) {
      console.error('Query error:', e.message);
      retries++;

      const evaluation = await evaluationChain.invoke({
        cypher,
        question: input.question,
        schema: graph.getSchema(),
        errors: [e.message],
      });

      cypher = evaluation.cypher;
    }
  }

  return results;
}

export default async function initCypherRetrievalChain(
  llm: BaseLanguageModel,
  graph: Neo4jGraph
) {
  // initiate answer chain
  const answerGeneration = await initGenerateAuthoritativeAnswerChain(llm);
  
  // return RunnablePassthrough
  return (
    RunnablePassthrough
    // Generate and evaluate the Cypher statement
    .assign({
      cypher: (input: { rephrasedQuestion: string }) =>
        recursivelyEvaluate(graph, llm, input.rephrasedQuestion),
    })

    // Get results from database
    .assign({
      results: (input: { cypher: string; question: string }) =>
        getResults(graph, llm, input),
    })

    // Extract information
    .assign({
      // Extract _id fields
      ids: (input: Omit<CypherRetrievalThroughput, "ids">) =>
        extractIds(input.results),
      // Convert results to JSON output
      context: ({ results }: Omit<CypherRetrievalThroughput, "ids">) =>
        Array.isArray(results) && results.length == 1
          ? JSON.stringify(results[0])
          : JSON.stringify(results),
    })

    // Save response to database
    .assign({
      output: (input: CypherRetrievalThroughput) =>
        answerGeneration.invoke({
          question: input.rephrasedQuestion,
          context: input.context,
        }),
    })

    // Return output
    .pick("output")
  );
}

================
File: src/modules/agent/tools/cypher/cypher-validator.class.ts
================
import { Neo4jGraph } from "@langchain/community/graphs/neo4j_graph";

export class Relationship {
  constructor(
    public from: string,
    public relationship: string,
    public to: string,
    public properties: Record<string, SchemaProperties>
  ) {}
}

export class Node {
  constructor(
    public label: string,
    public count: number,
    public properties: Record<string, SchemaProperties>
  ) {}
}

export enum RelationshipExistsDecision {
  NOT_FOUND,
  FOUND,
  REVERSE_DIRECTION,
}

export interface SchemaProperties {
  unique: boolean;
  indexed: boolean;
  type: string;
  existence: false;
  array: false;
}

interface SchemaValue {
  count: number;
  labels: string[];
  type: "node" | "relationship";
  properties: Record<string, SchemaProperties>;
  relationships: Record<
    string,
    {
      count: number;
      direction: "out" | "in";
      labels: string[];
      properties: Record<string, SchemaProperties>;
    }
  >;
}

let singleton: CypherValidator;

export class CypherValidator {
  private nodePattern: string = "\\(([^()]*?:[^()]*?)\\)";
  private relationshipPattern: string =
    "\\(([^()]*?:?[^()]*?)\\)(\\<)?-\\[([^\\]]+?)\\]-(\\>)?\\(([^()]*?:?[^()]*?)\\)";

  /* private */
  constructor(
    private readonly graph: Neo4jGraph | null,
    private nodes: Node[] = [],
    private relationships: Relationship[] = []
  ) {}

  /**
   * Reload the schema from the database
   *
   * @returns void
   */
  async reload(): Promise<void> {
    if (!this.graph) {
      return;
    }

    const res = await this.graph.query(`CALL apoc.meta.schema()`);

    if (!res) {
      throw new Error("Could not load schema");
    }

    const [first] = res;
    const rows: Record<string, SchemaValue> = first.value;

    // Build Relationships
    const relationships: Relationship[] = [];
    const nodes: Node[] = [];

    for (const [from, details] of Object.entries(rows)) {
      if (details.type === "node") {
        const node = new Node(from, details.count, details.properties);
        nodes.push(node);

        for (const [type, relDetails] of Object.entries(
          details.relationships
        )) {
          if (relDetails.direction == "out") {
            for (const to of relDetails.labels) {
              relationships.push(
                new Relationship(from, type, to, relDetails.properties)
              );
            }
          }
        }
      }
    }

    this.nodes = nodes;
    this.relationships = relationships;
  }

  /**
   * Get the schema as a string to stuff into a prompt
   *
   * @returns string
   */
  async getSchema(): Promise<string> {
    if (!this.nodes.length || !this.relationships.length) {
      await this.reload();
    }

    const properties = (node: Node | Relationship): string =>
      "{" +
      Object.entries(node.properties)
        .map(([k, v]) => `${k}: ${v.type}`)
        .join(", ") +
      "}";

    const nodes = `Nodes:\n- ${this.nodes
      .map((node) => `(:${node.label} ${properties(node)})`)
      .join("\n- ")}`;
    const relationships = `Relationships:\n- ${this.relationships
      .map(
        (relationship) =>
          `(:${relationship.from})-[:${relationship.relationship} ${properties(
            relationship
          )}]->(:${relationship.to})`
      )
      .join("\n- ")}`;

    return `${nodes}\n\n${relationships}`;
  }

  /**
   * @static
   * Create a new CypherValidator instance and load the schema from the graph
   *
   * @param {Neo4jGraph} graph
   * @returns {Promise<CypherValidator>}
   */
  static async load(graph: Neo4jGraph): Promise<CypherValidator> {
    if (!singleton) {
      singleton = new CypherValidator(graph);
    }

    await singleton.reload();

    return singleton;
  }

  /**
   * Verify that a node label exists in the schema
   *
   * @returns boolean
   */
  private verifyNodeLabel(label: string): boolean {
    return this.nodes.some((node) => node.label == label.trim());
  }

  /**
   * Extract labels from a node pattern
   *
   * @param {string} pattern
   * @returns {string[]}
   */
  private extractLabels(pattern: string | undefined): string[] {
    // Handle anonymous or node variables
    if (pattern === undefined || !pattern.includes(":")) {
      return [""];
    }

    // Strip brackets
    if (pattern.endsWith(")")) {
      pattern = pattern.substring(0, pattern.length - 1);
    }
    if (pattern.startsWith("(")) {
      pattern = pattern.substring(1);
    }

    if (pattern.includes("{")) {
      pattern = pattern.split("{")[0];
    }

    // Split labels
    if (pattern.includes(":")) {
      const labels = pattern.split(":");

      // Remove variable or empty string
      labels.splice(0, 1);

      return labels.map((label) => label.trim());
    }

    return [pattern];
  }

  /**
   * Extract relationship types from a relationship pattern
   *
   * @param {string} pattern
   * @returns {string[]}
   */
  private extractRelationshipTypes(pattern: string): string[] {
    let cleaned = pattern;

    // Strip brackets
    if (cleaned.includes("[")) {
      cleaned = cleaned.split("[")[1];
    }

    if (cleaned.includes("]")) {
      cleaned = cleaned.split("]")[0];
    }

    // Strip properties
    if (cleaned.includes("{")) {
      cleaned = cleaned.split("{")[0];
    }

    //  Strip variable
    if (cleaned.includes(":")) {
      const parts = cleaned.split(":");
      cleaned = parts[parts.length - 1];
    }
    // Strip variable length path
    if (cleaned.includes("*")) {
      const parts = cleaned.split("*");
      cleaned = parts[0];
    }

    return cleaned.split("|");
  }

  /**
   * Determine if any relationship exists between the given node labels.
   * If the relationship does not exist, check if the reverse direction exists
   * and if so, return the instruction to reverse the relationship.
   *
   * @param {string[]} from
   * @param {string[]} rel
   * @param {string[]} to
   * @returns {RelationshipExistsDecision}
   */
  private anyRelationshipExists(
    from: string[],
    rel: string[],
    to: string[]
  ): RelationshipExistsDecision {
    for (const f of from) {
      for (const t of to) {
        for (const r of rel) {
          if (this.relationshipExists(f, r, t)) {
            return RelationshipExistsDecision.FOUND;
          } else if (this.relationshipExists(t, r, f)) {
            return RelationshipExistsDecision.REVERSE_DIRECTION;
          }
        }
      }
    }
    return RelationshipExistsDecision.NOT_FOUND;
  }

  /**
   * Determine whether any of the relationship types exist
   *
   * @param {string[]} rels
   * @returns {boolean}
   */
  private anyRelationshipTypeExists(rels: string[]): boolean {
    for (const rel of rels) {
      if (this.relationshipTypeExists(rel)) {
        return true;
      }
    }
    return false;
  }

  /**
   * Determine whether the relationship type exists in the database
   *
   * @param {string} rel
   * @returns {boolean}
   */
  private relationshipTypeExists(rel: string): boolean {
    return this.relationships.some((schema) => schema.relationship == rel);
  }

  /**
   * Determine whether the relationship exists in the database
   *
   * @param {string} from
   * @param {string} rel
   * @param {string} to
   * @returns {boolean}
   */
  private relationshipExists(from: string, rel: string, to: string): boolean {
    if (from === "") {
      return this.relationships.some(
        (schema) => schema.relationship == rel && schema.to == to
      );
    } else if (to === "") {
      return this.relationships.some(
        (schema) => schema.relationship == rel && schema.from == from
      );
    } else {
      return this.relationships.some(
        (schema) =>
          schema.relationship == rel && schema.from == from && schema.to == to
      );
    }
  }

  /**
   * Helper function to consistently format the error message
   * when a node label is not found in the schema
   *
   * @param {string} label
   * @returns {string}
   */
  private noLabelError(label: string): string {
    return `Node label not found: ${label}`;
  }

  /**
   * Helper function to consistently format the error message
   * when the relationship types are not found in the schema
   *
   * @param {string[]} types
   * @returns {string}
   */
  private noRelationshipTypeError(types: string[]): string {
    return `Relationship type(s) not found: ${types.join("|")}`;
  }

  /**
   * Helper function to consistently format the error message
   * when the relationship type does not exist between the two nodes
   *
   * @param {string[]} types
   * @returns {string}
   */
  private noRelationshipError(
    from: string[],
    rel: string[],
    to: string[]
  ): string {
    return `Relationship combination not found: (:${from.join(
      ":"
    )})-[:${rel.join("|")}]->(:${to.join(":")})`;
  }

  /**
   * Given a query string, validate the query and return the query string and any errors.
   * If a relationship is written in the wrong direction, this function will correct it.
   * If any nodes or patterns do not exist, the details will be returned in the errors array.
   *
   * @param {string} query
   * @returns {{ query: string, errors: string[] }}
   */
  validate(query: string): { query: string; errors: string[] } {
    // Given a query string: MATCH (a:Person)-[:ACTED_IN]->(b:Movie) RETURN a, b)
    // Extract the pattern: (a:Person)-[:ACTED_IN]->(b:Movie)
    const errors = [];

    // Verify labels
    const nodePattern = new RegExp(`${this.nodePattern}`, "g");
    for (const node of query.matchAll(nodePattern)) {
      const labels = this.extractLabels(node[1]);

      for (const label of labels) {
        if (
          !label.includes(".") &&
          label.trim() !== "" &&
          !this.verifyNodeLabel(label)
        ) {
          errors.push(this.noLabelError(label));
        }
      }
    }

    const patternRegex = new RegExp(this.relationshipPattern, "g");
    const matches = query.matchAll(patternRegex);

    for (const match of matches) {
      const [pattern, left, incoming, rel, outgoing, right] = match;

      const leftLabels = this.extractLabels(left);
      const rightLabels = this.extractLabels(right);
      const relationshipTypes = this.extractRelationshipTypes(rel);

      if (!this.anyRelationshipTypeExists(relationshipTypes)) {
        errors.push(this.noRelationshipTypeError(relationshipTypes));
      }
      // - If direction is OUTGOING, find schema items where
      // `from` is the same as the first node label and `relationship`
      //  is the same as the relationship type
      else if (outgoing !== undefined) {
        const exists = this.anyRelationshipExists(
          leftLabels,
          relationshipTypes,
          rightLabels
        );

        if (exists === RelationshipExistsDecision.NOT_FOUND) {
          errors.push(
            this.noRelationshipError(leftLabels, relationshipTypes, rightLabels)
          );
        } else if (exists === RelationshipExistsDecision.REVERSE_DIRECTION) {
          query = query.replace(pattern, `(${left})<-[${rel}]-(${right})`);
        }
      }
      // - if direction is incomingm find schema items where `to` is the
      // same as the first node label and `relationship` is the same
      // as the relationship type
      else if (incoming !== undefined) {
        const exists = this.anyRelationshipExists(
          rightLabels,
          relationshipTypes,
          leftLabels
        );

        if (exists === RelationshipExistsDecision.NOT_FOUND) {
          errors.push(
            this.noRelationshipError(rightLabels, relationshipTypes, leftLabels)
          );
        } else if (exists === RelationshipExistsDecision.REVERSE_DIRECTION) {
          query = query.replace(pattern, `(${left})-[${rel}]->(${right})`);
        }
      }
    }

    return { query, errors };
  }

  call(query: string): string {
    const { query: correctedQuery, errors } = this.validate(query);

    if (errors.length > 0) {
      return `Your query: \n${query} has the following errors: \n${errors.join(
        "\n"
      )} `;
    }

    return correctedQuery;
  }
}

================
File: src/modules/agent/tools/index.ts
================
import { BaseChatModel } from "langchain/chat_models/base";
import { Embeddings } from "@langchain/core/embeddings";
import { Neo4jGraph } from "@langchain/community/graphs/neo4j_graph";
import initCypherRetrievalChain from "./cypher/cypher-retrieval.chain";
import initVectorRetrievalChain from "./vector-retrieval.chain";
import { DynamicStructuredTool } from "@langchain/community/tools/dynamic";
import { AgentToolInputSchema } from "../agent.types";
import { RunnableConfig } from "langchain/runnables";

export default async function initTools(
  llm: BaseChatModel,
  embeddings: Embeddings,
  graph: Neo4jGraph
): Promise<DynamicStructuredTool[]> {
  const cypherChain = await initCypherRetrievalChain(llm, graph);
  const retrievalChain = await initVectorRetrievalChain(llm, embeddings);

  return [
    new DynamicStructuredTool({
      name: "graph-cypher-retrieval-chain",
      description:
        "For retrieving movie information from the database including movie recommendations, actors and user ratings",
      schema: AgentToolInputSchema,
      func: (input, _runManager, config) => cypherChain.invoke(input, config),
    }),
    new DynamicStructuredTool({
      name: "graph-vector-retrieval-chain",
      description:
        "For finding movies, comparing movies by their plot or recommending a movie based on a theme",
      schema: AgentToolInputSchema,
      func: (input, _runManager: any, config) =>
        retrievalChain.invoke(input, config),
    }),
  ];
}

================
File: src/modules/agent/tools/vector-retrieval.chain.ts
================
import {
  Runnable,
  RunnablePassthrough,
  RunnablePick,
} from "@langchain/core/runnables";
import { Embeddings } from "@langchain/core/embeddings";
import initGenerateAnswerChain from "../chains/answer-generation.chain";
import { BaseLanguageModel } from "langchain/base_language";
import initVectorStore from "../vector.store";
import { saveHistory } from "../history";
import { DocumentInterface } from "@langchain/core/documents";
import { AgentToolInput } from "../agent.types";
import { init } from "next/dist/compiled/webpack/webpack";

type RetrievalChainThroughput = AgentToolInput & {
  context: string;
  output: string;
  ids: string[];
};

// Helper function to extract document IDs from Movie node metadata
const extractDocumentIds = (
  documents: DocumentInterface<{ _id: string; [key: string]: any }>[]
): string[] => documents.map((document) => document.metadata._id);

// Convert documents to string to be included in the prompt
const docsToJson = (documents: DocumentInterface[]) =>
  JSON.stringify(documents);

export default async function initVectorRetrievalChain(
  llm: BaseLanguageModel,
  embeddings: Embeddings
): Promise<Runnable<AgentToolInput, string>> {
  //  Create vector store instance
  const vectorStore = await initVectorStore(embeddings);

  // Initialize a retriever wrapper around the vector store
  const vectorStoreRetriever = vectorStore.asRetriever(5);

  // Initialize  Answer Chain
  const answerChain = initGenerateAnswerChain(llm);

  // Get the rephrased question and generate context
  return (
    RunnablePassthrough.assign({
      documents: new RunnablePick("rephrasedQuestion").pipe(
        vectorStoreRetriever
      ),
    })
      .assign({
        // Extract the IDs
        ids: new RunnablePick("documents").pipe(extractDocumentIds),
        // convert documents to string
        context: new RunnablePick("documents").pipe(docsToJson),
      })
      .assign({
        output: (input: RetrievalChainThroughput) =>
          answerChain.invoke({
            question: input.rephrasedQuestion,
            context: input.context,
          }),
      })
      .assign({
        responseId: async (input: RetrievalChainThroughput, options) =>
          saveHistory(
            options?.config.configurable.sessionId,
            "vector",
            input.input,
            input.rephrasedQuestion,
            input.output,
            input.ids
          ),
      })
      .pick("output")
  );
}

================
File: src/modules/agent/vector.store.ts
================
import { EmbeddingsInterface } from "@langchain/core/embeddings";
import { Neo4jVectorStore } from "@langchain/community/vectorstores/neo4j_vector";

/**
 * Create a new vector search index that uses the existing
 * `moviePlots` index.
 *
 * @param {EmbeddingsInterface} embeddings  The embeddings model
 * @returns {Promise<Neo4jVectorStore>}
 */
export default async function initVectorStore(
  embeddings: EmbeddingsInterface
): Promise<Neo4jVectorStore> {
  const vectorStore = await Neo4jVectorStore.fromExistingIndex(embeddings, { 
    url: process.env.NEO4J_URI as string,
    username: process.env.NEO4J_USERNAME as string,
    password: process.env.NEO4J_PASSWORD as string,
    indexName: "moviePlots",
    textNodeProperty: "plot",
    embeddingNodeProperty: "embedding",
    retrievalQuery: `
      RETURN
        node.plot AS text,
        score,
        {
          _id: elementid(node),
          title: node.title,
          directors: [ (person)-[:DIRECTED]->(node) | person.name ],
          actors: [ (person)-[r:ACTED_IN]->(node) | [person.name, r.role] ],
          tmdbId: node.tmdbId,
          source: 'https://www.themoviedb.org/movie/'+ node.tmdbId
        } AS metadata
    `,
   })
  return vectorStore;
}

================
File: src/modules/graph.ts
================
import { Neo4jGraph } from "@langchain/community/graphs/neo4j_graph";

// <1> The singleton instance
let graph: Neo4jGraph;

/**
 * <2> Return the existing `graph` object or create one
 * has not already been created
 * @returns {Promise<Neo4jGraph>}
 */
export async function initGraph(): Promise<Neo4jGraph> {
  if (!graph) {
    graph = await Neo4jGraph.initialize({
      url: process.env.NEO4J_URI as string,
      username: process.env.NEO4J_USERNAME as string,
      password: process.env.NEO4J_PASSWORD as string,
      database: process.env.NEO4J_DATABASE as string | undefined,
    });
  }

  return graph;
}

/**
 * Close any connections to Neo4j initiated in this file.
 *
 * @returns {Promise<void>}
 */
export async function close(): Promise<void> {
  if (graph) {
    await graph.close();
  }
}

================
File: src/modules/llm.ts
================
import { ChatOpenAI, OpenAIEmbeddings } from "@langchain/openai";

export const llm = new ChatOpenAI({
  openAIApiKey: process.env.OPENAI_API_KEY,
  modelName: "gpt-4",
  temperature: 0,
});

export const embeddings = new OpenAIEmbeddings({
  openAIApiKey: process.env.OPENAI_API_KEY as string,
});

================
File: src/pages/api/chat.ts
================
import { call } from "@/modules/agent";
import { randomUUID } from "crypto";
import type { NextApiRequest, NextApiResponse } from "next";

type ResponseData = {
  message: string;
};

function getSessionId(req: NextApiRequest, res: NextApiResponse): string {
  let sessionId: string | undefined = req.cookies["session"];

  if (typeof sessionId === "string") {
    return sessionId;
  }

  // Assign a new session
  sessionId = randomUUID();
  res.setHeader("Set-Cookie", `session=${sessionId}`);

  return sessionId;
}

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse<ResponseData>
) {
  if (req.method === "POST") {
    const body = JSON.parse(req.body);
    const message = body.message;

    // Get or assign the Session ID
    const sessionId = getSessionId(req, res);

    try {
      const result = await call(message, sessionId);

      res.status(201).json({
        message: result,
      });
    } catch (e: any) {
      res.status(500).json({
        message: `I'm suffering from brain fog...\n\n${e.message}`,
      });
    }
  } else {
    res.status(404).send({ message: "Route not found" });
  }
}

================
File: src/utils.ts
================
export function sleep(ms = 500): Promise<void> {
  return new Promise((resolve) => {
    setTimeout(resolve, ms);
  });
}

// tag::extractids[]
export function extractIds(input: any): string[] {
  let output: string[] = [];

  // Function to handle an object
  const handleObject = (item: any) => {
    for (const key in item) {
      if (key === "_id") {
        if (!output.includes(item[key])) {
          output.push(item[key]);
        }
      } else if (typeof item[key] === "object" && item[key] !== null) {
        // Recurse into the object if it is not null
        output = output.concat(extractIds(item[key]));
      }
    }
  };

  if (Array.isArray(input)) {
    // If the input is an array, iterate over each element
    input.forEach((item) => {
      if (typeof item === "object" && item !== null) {
        handleObject(item);
      }
    });
  } else if (typeof input === "object" && input !== null) {
    // If the input is an object, handle it directly
    handleObject(input);
  }

  return output;
}
// end::extractids[]

================
File: tailwind.config.js
================
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    "./app/**/*.{js,ts,jsx,tsx,mdx}",
    "./pages/**/*.{js,ts,jsx,tsx,mdx}",
    "./components/**/*.{js,ts,jsx,tsx,mdx}",

    // Or if using `src` directory:
    "./src/**/*.{js,ts,jsx,tsx,mdx}",
  ],
  plugins: [],
};

================
File: tsconfig.json
================
{
  "compilerOptions": {
    "lib": [
      "dom",
      "dom.iterable",
      "esnext"
    ],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "target": "es2017",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": [
        "./src/*"
      ]
    }
  },
  "include": [
    "src/**/*, next-env.d.ts",
    "**/*.ts",
    "**/*.tsx",
    ".next/types/**/*.ts"
  ],
  "exclude": [
    "node_modules",
    "src/solutions/**/*.ts"
  ]
}
